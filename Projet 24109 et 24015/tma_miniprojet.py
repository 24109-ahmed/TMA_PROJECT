# -*- coding: utf-8 -*-
"""tma_miniprojet.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RoDtqutO6kIffeZq1ON_AKJyjVUioWQX
"""



!pip install numpy scipy matplotlib soundfile
!apt-get install ffmpeg -y

import numpy as np
import matplotlib.pyplot as plt
from scipy.io import wavfile
from scipy.fft import fft, fftfreq
from google.colab import output
from IPython.display import Javascript, display, Audio
import base64
import soundfile as sf


def record_audio(seconds=5, filename="ma_voix.wav"):

    print("Autorisez le microphone puis parlez...")

    js = Javascript("""
    async function record(sec){
      const stream = await navigator.mediaDevices.getUserMedia({audio:true});
      const context = new AudioContext();
      const source = context.createMediaStreamSource(stream);
      const recorder = context.createScriptProcessor(4096,1,1);

      let data = [];

      recorder.onaudioprocess = e => {
        data.push(...e.inputBuffer.getChannelData(0));
      };

      source.connect(recorder);
      recorder.connect(context.destination);

      await new Promise(r => setTimeout(r, sec*1000));

      recorder.disconnect();
      source.disconnect();

      return data;
    }
    """)

    display(js)

    audio = output.eval_js(f"record({seconds})")

    audio = np.array(audio)

    sf.write(filename, audio, 44100)

    print("Enregistrement terminé")

    return audio, 44100



signal, fs = record_audio(5)

print("Fréquence d'échantillonnage:", fs)
print("Durée:", len(signal)/fs, "secondes")


display(Audio(signal, rate=fs))



t = np.linspace(0, len(signal)/fs, len(signal))

plt.figure(figsize=(12,4))
plt.plot(t, signal)
plt.title("Signal temporel")
plt.xlabel("Temps (s)")
plt.ylabel("Amplitude")
plt.grid()
plt.show()



N = len(signal)

fft_signal = fft(signal)

freq = fftfreq(N, 1/fs)

mask = freq > 0

plt.figure(figsize=(12,4))
plt.plot(freq[mask], np.abs(fft_signal)[mask])

plt.title("Spectre fréquentiel")
plt.xlabel("Fréquence (Hz)")
plt.ylabel("Amplitude")
plt.xlim(0,2000)

plt.grid()
plt.show()


index = np.argmax(np.abs(fft_signal)[mask])

pitch = freq[mask][index]

print("=================================")
print(" Pitch =", round(pitch,2), "Hz")

if pitch < 165:
    print("Voix grave")
else:
    print("Voix aiguë")
print("=================================")