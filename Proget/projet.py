# ===========================
# 1Ô∏è‚É£ Introduction
# ===========================

# Mini-Projet : L‚ÄôArch√©ologue Acoustique (NASA/JFK)
# Objectif : Analyse spectrale des voix du bin√¥me et restauration d‚Äôun discours JFK bruit√©
# Outils : Python, NumPy, SciPy, Matplotlib, Librosa

import numpy as np
import matplotlib.pyplot as plt
import librosa
import librosa.display
from scipy.signal import iirnotch, lfilter

# ===========================
# 2Ô∏è‚É£ Partie Obligatoire : Analyse de la Voix
# ===========================

# ‚ö° Charger les fichiers audio d√©j√† enregistr√©s
# Remplacez par vos fichiers audio
audio_files = {
    "Ahmed": "Ahmed.wav",
    "Mohamed": "Mohamed.wav"
}

voices = {}
sr_dict = {}

for name, file in audio_files.items():
    y, sr = librosa.load(file, sr=None)
    voices[name] = y
    sr_dict[name] = sr
    print(f"{name} : dur√©e = {len(y)/sr:.2f} s, fr√©quence d'√©chantillonnage = {sr} Hz")

# ‚ö° Affichage du signal temporel
plt.figure(figsize=(12, 6))
for name, y in voices.items():
    plt.plot(np.linspace(0, len(y)/sr_dict[name], len(y)), y, label=name)
plt.title("Signal temporel des voix")
plt.xlabel("Temps (s)")
plt.ylabel("Amplitude")
plt.legend()
plt.show()

# ‚ö° FFT et visualisation spectrale
plt.figure(figsize=(12, 6))
for name, y in voices.items():
    Y = np.fft.fft(y)
    freqs = np.fft.fftfreq(len(y), 1/sr_dict[name])
    plt.plot(freqs[:len(freqs)//2], np.abs(Y[:len(Y)//2]), label=name)
plt.title("Spectre des voix")
plt.xlabel("Fr√©quence (Hz)")
plt.ylabel("Amplitude")
plt.legend()
plt.show()

# ‚ö° D√©tection du Pitch (fr√©quence fondamentale)
def detect_pitch(y, sr):
    Y = np.fft.fft(y)
    freqs = np.fft.fftfreq(len(y), 1/sr)
    idx = np.argmax(np.abs(Y[:len(Y)//2]))
    return freqs[idx]

for name, y in voices.items():
    pitch = detect_pitch(y, sr_dict[name])
    print(f"{name} : fr√©quence fondamentale ‚âà {pitch:.1f} Hz")

# ===========================
# 3Ô∏è‚É£ Pr√©sentation du probl√®me NASA
# ===========================

# Chargement du signal bruit√© JFK
jfk_file = "JFK_noisy.wav"
jfk, sr_jfk = librosa.load(jfk_file, sr=None)
print(f"Signal JFK : dur√©e = {len(jfk)/sr_jfk:.2f} s, fr√©quence d'√©chantillonnage = {sr_jfk} Hz")

plt.figure(figsize=(12, 4))
plt.plot(np.linspace(0, len(jfk)/sr_jfk, len(jfk)), jfk)
plt.title("Signal JFK bruit√©")
plt.xlabel("Temps (s)")
plt.ylabel("Amplitude")
plt.show()

# ===========================
# 4Ô∏è‚É£ Analyse spectrale du signal bruit√©
# ===========================

# FFT du signal JFK
Y_jfk = np.fft.fft(jfk)
freqs_jfk = np.fft.fftfreq(len(jfk), 1/sr_jfk)

plt.figure(figsize=(12,6))
plt.plot(freqs_jfk[:len(freqs_jfk)//2], np.abs(Y_jfk[:len(Y_jfk)//2]))
plt.title("Spectre du signal JFK bruit√©")
plt.xlabel("Fr√©quence (Hz)")
plt.ylabel("Amplitude")
plt.show()

# ===========================
# 5Ô∏è‚É£ Conception du filtre Notch (1000 Hz)
# ===========================

# Param√®tres du filtre
f0 = 1000  # Hz du sifflement
Q = 30     # facteur de qualit√©
b, a = iirnotch(f0, Q, sr_jfk)

# Application du filtre
jfk_notch = lfilter(b, a, jfk)

# ===========================
# 6Ô∏è‚É£ Soustraction spectrale (bruit blanc)
# ===========================

# Estimation du spectre du bruit blanc (premiers 0.5s)
noise = jfk[:int(0.5*sr_jfk)]
noise_spectrum = np.fft.fft(noise)
jfk_spectrum = np.fft.fft(jfk_notch)

# Soustraction spectrale (amplitude)
clean_spectrum = jfk_spectrum - np.mean(np.abs(noise_spectrum))
# Reconstruction du signal
jfk_clean = np.fft.ifft(clean_spectrum).real

# ===========================
# 7Ô∏è‚É£ R√©sultats (Avant / Apr√®s)
# ===========================

plt.figure(figsize=(12,6))
plt.plot(np.linspace(0, len(jfk)/sr_jfk, len(jfk)), jfk, label="JFK bruit√©")
plt.plot(np.linspace(0, len(jfk_clean)/sr_jfk, len(jfk_clean)), jfk_clean, label="JFK restaur√©")
plt.title("Signal JFK : Avant / Apr√®s restauration")
plt.xlabel("Temps (s)")
plt.ylabel("Amplitude")
plt.legend()
plt.show()

# ===========================
# 8Ô∏è‚É£ Calcul du SNR
# ===========================

def compute_snr(signal, noise):
    return 10*np.log10(np.sum(signal**2)/np.sum(noise**2))

# Bruit estim√© = signal bruit√© - signal restaur√©
noise_est = jfk - jfk_clean
snr_before = compute_snr(jfk, noise)
snr_after = compute_snr(jfk_clean, noise_est)

print(f"SNR avant traitement ‚âà {snr_before:.2f} dB")
print(f"SNR apr√®s traitement ‚âà {snr_after:.2f} dB")

# ===========================
# 9Ô∏è‚É£ Discussion
# ===========================
print("""
Analyse :
- Le filtre Notch a efficacement supprim√© le sifflement √† 1000 Hz.
- La soustraction spectrale a r√©duit le bruit blanc.
- Difficult√© : s√©parer compl√®tement les voix si elles sont m√©lang√©es (BSS)
""")

# ===========================
# üîü Conclusion
# ===========================
print("""
Conclusion :
- Apprentissage : FFT, filtrage Notch, soustraction spectrale, SNR
- Am√©liorations possibles : filtrage adaptatif, analyse multi-canaux, m√©thodes BSS plus avanc√©es
""")

# ===========================
# 1Ô∏è‚É£1Ô∏è‚É£ R√©f√©rences
# ===========================
print("""
R√©f√©rences :
- JFK audio archive : https://www.archives.gov/
- Biblioth√®ques Python : NumPy, SciPy, Librosa, Matplotlib
""")